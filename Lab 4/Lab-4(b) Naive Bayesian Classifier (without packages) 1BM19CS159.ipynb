{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4db10a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6be3fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This make sures that the dataset is in an ordered format. If we have some arbirary names in that column it difficult to deal with that.\n",
    "\n",
    "def encode_class(dataset):\n",
    "  classes=[]\n",
    "  for i in range(len(dataset)):\n",
    "    if dataset[i][-1] not in classes:\n",
    "      classes.append(dataset[i][-1])\n",
    "  \n",
    "  # Looping across the classes which we have derived above.This will make sure that we have definitive classes (numeric) and not arbitrary\n",
    "  for i in range(len(classes)):\n",
    "    # Looping across all rows of dataset\n",
    "    for j in range(len(dataset)):\n",
    "      if dataset[j][-1] == classes[i]:\n",
    "        dataset[j][-1]=i\n",
    "  return dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b947eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data between training set and testing set. Normally its a general understanding the training:testing=7:3\n",
    "\n",
    "def train_test_split(dataset,ratio):\n",
    "  test_num=int(ratio*len(dataset))\n",
    "  train=list(dataset)\n",
    "  test=[]\n",
    "  for i in range(test_num):\n",
    "    rand=random.randrange(len(train))\n",
    "    test.append(train.pop(rand))\n",
    "  return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3cc50f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now depending on resultant value (last column values), we need to group the rows. It will be usefult for calculating mean and std_dev\n",
    "\n",
    "def groupUnderClass(train):\n",
    "  dict={}\n",
    "  for row in train:\n",
    "    if row[-1] not in dict:\n",
    "      dict[row[-1]]=[]\n",
    "    dict[row[-1]].append(row)\n",
    "  return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d910c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard formulae (just by-heart)\n",
    "\n",
    "def mean(val):\n",
    "  return sum(val)/float(len(val)) #Obvious\n",
    "\n",
    "def stdDev(val):\n",
    "  avg=mean(val)\n",
    "  variance=sum([pow(x-avg,2) for x in val])/float(len(val)-1) # Especially this one\n",
    "  return math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a708c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will calculte the mean and std dev with respect to each attribute. Important while calculating gaussian probablity\n",
    "\n",
    "def meanStdDev(instances):\n",
    "  info=[(mean(x),stdDev(x)) for x in zip(*instances)] # Here we are taking complete column's values of all instances.\n",
    "  del info[-1]\n",
    "  return info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07410b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As explained earlier why e need to group. We will be calculating the mean and std dev with respect each class.\n",
    "\n",
    "def MeanAndStdDevForClass(train):\n",
    "  info={}\n",
    "  dictionary=groupUnderClass(train)\n",
    "  # print(dictionary)\n",
    "  for key,value in dictionary.items():\n",
    "    # dictionary[key]=meanStdDev(value)\n",
    "    info[key]=meanStdDev(value) #Here value stands for a complete group.\n",
    "  return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40bcf7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Its a formula by heart (no choice)\n",
    "\n",
    "def calculateGaussianProbablity(x,mean,std_dev):\n",
    "  expo = math.exp(-(math.pow(x - mean, 2) / (2 * math.pow(std_dev, 2))))\n",
    "  return (1 / (math.sqrt(2 * math.pi) * std_dev)) * expo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "130ab8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After calculating mean and std dev w.r.t training data now its time to check if the logic will work on testing data\n",
    "\n",
    "\n",
    "def calculateClassProbablities(info,ele):\n",
    "  probablities={}\n",
    "  for key,summaries in info.items(): # Info contains the groupName (key) and list of (mean,std_dev) for each attribute of that group\n",
    "    probablities[key]=1\n",
    "    for i in range(len(summaries)): #Loop across all attributes \n",
    "      mean,std_dev=summaries[i]\n",
    "      x=ele[i] # Testing data's one instance's attribute value.\n",
    "      probablities[key] *= calculateGaussianProbablity(x, mean, std_dev)\n",
    "  return probablities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bce7dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(info,ele):\n",
    "  probablities=calculateClassProbablities(info,ele) # returns a dictionary of probablities for each group\n",
    "  bestLabel,bestProb=None,-1\n",
    "  # Consider group name whichever gives you the highest probablities for this instance of testing data \n",
    "  for key,prob in probablities.items():\n",
    "    if bestLabel==None or prob>bestProb:\n",
    "      bestProb=prob\n",
    "      bestLabel=key\n",
    "  return bestLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0515b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop across testing data and store the predicted result from our model in the list.\n",
    "\n",
    "def getPredictions(info,test):\n",
    "  predictions=[]\n",
    "  for ele in test:\n",
    "    result=predict(info,ele) # This will give you the group to which it will belong.\n",
    "    predictions.append(result)\n",
    "  return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6415e3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(predictions,test):\n",
    "  count=0\n",
    "  for i in range(len(test)):\n",
    "    if predictions[i]==test[i][-1]:\n",
    "      count+=1\n",
    "  return count/float(len(test))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df87ec77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75.21739130434783"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename=r\"C:\\Users\\Admin\\OneDrive\\Desktop\\6th sem\\ML\\lab-ml\\Lab 4\\pima-indians-diabetes.csv\"\n",
    "dataset=csv.reader(open(filename))\n",
    "dataset=list(dataset)\n",
    "dataset=encode_class(dataset)\n",
    "for i in range(len(dataset)):\n",
    "  dataset[i]=[float(x) for x in dataset[i]]\n",
    "\n",
    "ratio=0.3\n",
    "print(len(dataset))\n",
    "train,test=train_test_split(dataset,ratio)\n",
    "info=MeanAndStdDevForClass(train)\n",
    "\n",
    "predictions=getPredictions(info,test)\n",
    "accuracy=check_accuracy(predictions,test)\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e63269b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
